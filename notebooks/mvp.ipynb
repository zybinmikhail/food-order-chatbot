{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1243c786-1a55-4e20-95d2-3be59d661f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mikhail_zybin/food-order-chat-bot/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7ee154-0edc-4cdb-ada0-7d2b1da0dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb5862c-70bb-4518-8912-6383fab8acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot import (\n",
    "    initialize_system_prompt,\n",
    "    make_conversation,\n",
    "    initialize_messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b11678c-d6d7-47d1-b04c-18c3dd96a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_base = \"https://llama3-1-8b-api.llm.lab.epam.com/v1\"\n",
    "model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "client = openai.OpenAI(api_key=\"***REMOVED***\", base_url=api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e56888-5416-46a9-a90c-c9380df1a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello, Dear Customer!\n",
      "\n",
      "I am food order chatbot! My function is to help you choose and order food from various cafes and restaurants.\n",
      "\n",
      "What would you like to eat today?\n",
      "You: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what pasta options do you havw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:23:45.683\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1mBased on the conversation between the chatbot and the user, we can analyze the user's replies and the order summary made by the chatbot.\n",
      "\n",
      "The user has not told the chatbot what restaurant they have chosen to have order from. The chatbot has not asked the user about the restaurant yet.\n",
      "\n",
      "The user has asked about pasta options, but they have not ordered any dishes yet.\n",
      "\n",
      "The user has not provided the chatbot with the information about what dishes they want to order.\n",
      "\n",
      "The user has not provided the chatbot with the information about what delivery time they have chosen.\n",
      "\n",
      "Here is the output in the required format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"dish_names\": [],\n",
      "  \"dish_quantities\": [],\n",
      "  \"restaurant_name\": \"\",\n",
      "  \"delivery_time\": \"\"\n",
      "}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: We have several pasta options available from different restaurants. \n",
      "\n",
      "From Roman Holiday, we have:\n",
      "- Spaghetti Carbonara (pasta) ($14.99)\n",
      "- Lasagna al Forno ($13.99)\n",
      "- Gnocchi alla Sorrentina ($11.99)\n",
      "\n",
      "From Sukhothai, we have:\n",
      "- Chicken Pad See Ew ($11.99)\n",
      "\n",
      "If you're interested in ordering pasta, I would recommend choosing between these options. Which one sounds appealing to you?\n",
      "You: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " add 3 Lasagna al Forno, 5 Gnocchi alla Sorrentina, 2 Spaghetti Carbonara\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:27:26.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1mBased on the conversation between the chatbot and the user, the user has chosen to order Lasagna al Forno, Gnocchi alla Sorrentina, and Spaghetti Carbonara from Roman Holiday.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"dish_names\": [\"Lasagna al Forno\", \"Gnocchi alla Sorrentina\", \"Spaghetti Carbonara\"],\n",
      "  \"dish_quantities\": [3, 5, 2],\n",
      "  \"restaurant_name\": \"Roman Holiday\",\n",
      "  \"delivery_time\": \"\"\n",
      "}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: You'd like to order:\n",
      "\n",
      "- 3 Lasagna al Forno ($13.99 x 3 = $41.97)\n",
      "- 5 Gnocchi alla Sorrentina ($11.99 x 5 = $59.95)\n",
      "- 2 Spaghetti Carbonara ($14.99 x 2 = $29.98)\n",
      "\n",
      "Total cost: $41.97 + $59.95 + $29.98 = $132.90\n",
      "\n",
      "Now, let's talk about the restaurant. Since you're ordering pasta, I would recommend choosing Roman Holiday as your restaurant. They have a wide variety of pasta dishes, and the ones you've chosen are all part of their menu.\n",
      "\n",
      "Would you like to order from Roman Holiday?\n",
      "You: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes, I want to order from ROman Holiday. Remove 1 Spaghetti Carbonara and 1 Gnocchi alla Sorrentina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:29:19.304\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1m```json\n",
      "{\n",
      "  \"dish_names\": [\"Lasagna al Forno\", \"Gnocchi alla Sorrentina\", \"Spaghetti Carbonara\"],\n",
      "  \"dish_quantities\": [3, 5, 2],\n",
      "  \"restaurant_name\": \"Roman Holiday\",\n",
      "  \"delivery_time\": \"\"\n",
      "}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: You'd like to remove 1 Spaghetti Carbonara and 1 Gnocchi alla Sorrentina from your order.\n",
      "\n",
      "Here's the updated order:\n",
      "\n",
      "- 3 Lasagna al Forno ($13.99 x 3 = $41.97)\n",
      "- 4 Gnocchi alla Sorrentina ($11.99 x 4 = $47.96)\n",
      "- 1 Spaghetti Carbonara ($14.99)\n",
      "\n",
      "Total cost: $41.97 + $47.96 + $14.99 = $104.92\n",
      "\n",
      "Your order is now complete. Let's move on to the delivery details.\n",
      "\n",
      "When would you like to receive your order? Would you like it delivered within the next hour, or would you prefer a specific time today or tomorrow?\n",
      "You: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes, this is correct. Deliver within the next hoour please\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:29:56.250\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1m```json\n",
      "{\n",
      "  \"dish_names\": [\"Lasagna al Forno\", \"Gnocchi alla Sorrentina\", \"Spaghetti Carbonara\"],\n",
      "  \"dish_quantities\": [3, 4, 1],\n",
      "  \"restaurant_name\": \"Roman Holiday\",\n",
      "  \"delivery_time\": \"within the next hour\"\n",
      "}\n",
      "```\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: You have chosen to order 3 portions of Lasagna al Forno, 4 portions of Gnocchi alla Sorrentina, 1 portion of Spaghetti Carbonara from Roman Holiday by within the next hour. Is that accurate?\n",
      "You: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Yes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:32:24.122\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1m```json\n",
      "{\n",
      "  \"dish_names\": [\"Lasagna al Forno\", \"Gnocchi alla Sorrentina\", \"Spaghetti Carbonara\"],\n",
      "  \"dish_quantities\": [3, 4, 1],\n",
      "  \"restaurant_name\": \"Roman Holiday\",\n",
      "  \"delivery_time\": \"within the next hour\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\u001b[32m2024-12-13 16:32:24.125\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mget_next_ai_message\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mDetermining if the order is made and confirmed\u001b[0m\n",
      "\u001b[32m2024-12-13 16:32:24.870\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mparse_llm_json\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1m{\n",
      "  \"meaning\": 1\n",
      "}\u001b[0m\n",
      "\u001b[32m2024-12-13 16:32:24.874\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mchatbot\u001b[0m:\u001b[36mget_next_ai_message\u001b[0m:\u001b[36m141\u001b[0m - \u001b[34m\u001b[1mIs the conversation finished1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Your order of 3 portions of Lasagna al Forno, 4 portions of Gnocchi alla Sorrentina, 1 portion of Spaghetti Carbonara from Roman Holiday was successfully received and will be delivered to you by within the next hour\n"
     ]
    }
   ],
   "source": [
    "messages = initialize_messages()\n",
    "make_conversation(messages, model, client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-order-chat-bot",
   "language": "python",
   "name": "food-order-chat-bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
